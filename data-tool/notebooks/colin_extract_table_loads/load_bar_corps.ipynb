{
    "cells":
    [
        {
            "metadata":
            {},
            "cell_type": "markdown",
            "source":
            [
                "# Load BAR Corps Table Notebook\n",
                "\n",
                "## Purpose\n",
                "This notebook automates the population of the `bar_corps` table in the COLIN Extract database.\n",
                "It pulls data from:\n",
                "1. **BAR Database** - Business AR filing data\n",
                "2. **Auth Database** - Account mailing address information\n",
                "\n",
                "## Process Overview\n",
                "1. Truncate the `bar_corps` table in COLIN Extract\n",
                "2. Query BAR database for business filing records\n",
                "3. Query Auth database for mailing address status by org/business\n",
                "4. Merge data and derive `bar_account_has_mailing_address` flag\n",
                "5. Load merged data into `bar_corps` table\n",
                "6. Optionally refresh the `mv_legacy_corps_data` materialized view\n",
                "\n",
                "## Prerequisites\n",
                "- `.env` file with database credentials\n",
                "- Network access to BAR, Auth, and COLIN Extract databases\n",
                "- `bar_corps` table must have the `bar_account_has_mailing_address` column\n",
                "\n",
                "---"
            ],
            "id": "7c9f88ac871d9953"
        },
        {
            "metadata":
            {},
            "cell_type": "markdown",
            "source": "## Install Required Packages",
            "id": "9777c45acf0720f1"
        },
        {
            "metadata":
            {},
            "cell_type": "code",
            "source":
            [
                "%pip install pandas\n",
                "%pip install sqlalchemy>=2.0\n",
                "%pip install python-dotenv\n",
                "%pip install psycopg2-binary\n",
                "%pip install openpyxl"
            ],
            "id": "8de955c822718828",
            "outputs":
            [],
            "execution_count": null
        },
        {
            "metadata":
            {},
            "cell_type": "markdown",
            "source": "## Imports and Environment Setup",
            "id": "3b02ec644ca3892f"
        },
        {
            "metadata":
            {},
            "cell_type": "code",
            "source":
            [
                "import os\n",
                "from datetime import datetime\n",
                "from typing import Optional\n",
                "\n",
                "import pandas as pd\n",
                "from sqlalchemy import create_engine, text\n",
                "from sqlalchemy.exc import SQLAlchemyError, OperationalError\n",
                "from sqlalchemy.engine import Engine\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "# Load environment variables\n",
                "load_dotenv()\n",
                "print(\"Environment variables loaded successfully.\")"
            ],
            "id": "570867bf5e50e9cf",
            "outputs":
            [],
            "execution_count": null
        },
        {
            "metadata":
            {},
            "cell_type": "markdown",
            "source":
            [
                "## Database Configuration\n",
                "\n",
                "Configure connections to:\n",
                "- **colin_extract**: Target database for `bar_corps` table\n",
                "- **bar**: Source database for business AR filing data\n",
                "- **auth**: Source database for account mailing address data"
            ],
            "id": "c749be2284248574"
        },
        {
            "metadata":
            {},
            "cell_type": "code",
            "source":
            [
                "DATABASE_CONFIG = {\n",
                "    'colin_extract': {\n",
                "        'username': os.getenv(\"DATABASE_COLIN_EXTRACT_USERNAME\"),\n",
                "        'password': os.getenv(\"DATABASE_COLIN_EXTRACT_PASSWORD\"),\n",
                "        'host': os.getenv(\"DATABASE_COLIN_EXTRACT_HOST\"),\n",
                "        'port': os.getenv(\"DATABASE_COLIN_EXTRACT_PORT\"),\n",
                "        'name': os.getenv(\"DATABASE_COLIN_EXTRACT_NAME\")\n",
                "    },\n",
                "    'bar': {\n",
                "        'username': os.getenv(\"DATABASE_BAR_USERNAME\"),\n",
                "        'password': os.getenv(\"DATABASE_BAR_PASSWORD\"),\n",
                "        'host': os.getenv(\"DATABASE_BAR_HOST\"),\n",
                "        'port': os.getenv(\"DATABASE_BAR_PORT\"),\n",
                "        'name': os.getenv(\"DATABASE_BAR_NAME\")\n",
                "    },\n",
                "    'auth': {\n",
                "        'username': os.getenv(\"DATABASE_AUTH_USERNAME\"),\n",
                "        'password': os.getenv(\"DATABASE_AUTH_PASSWORD\"),\n",
                "        'host': os.getenv(\"DATABASE_AUTH_HOST\"),\n",
                "        'port': os.getenv(\"DATABASE_AUTH_PORT\"),\n",
                "        'name': os.getenv(\"DATABASE_AUTH_NAME\")\n",
                "    },\n",
                "}\n",
                "\n",
                "# Build connection URIs\n",
                "for db_key, db_config in DATABASE_CONFIG.items():\n",
                "    # Validate config\n",
                "    missing_keys = [k for k, v in db_config.items() if v is None]\n",
                "    if missing_keys:\n",
                "        print(f\"{db_key.upper()}: Missing environment variables for: {missing_keys}\")\n",
                "\n",
                "    # Build PostgreSQL URI\n",
                "    uri = f\"postgresql://{db_config['username']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['name']}\"\n",
                "    DATABASE_CONFIG[db_key] = {'uri': uri}\n",
                "\n",
                "print(\"Database configurations built successfully.\")"
            ],
            "id": "9e8599fcf7858f50",
            "outputs":
            [],
            "execution_count": null
        },
        {
            "metadata":
            {},
            "cell_type": "markdown",
            "source": "## Create and Test Database Engines",
            "id": "bf2d188fd3fc5123"
        },
        {
            "metadata":
            {},
            "cell_type": "code",
            "source":
            [
                "engines = {}\n",
                "\n",
                "for db_key, config in DATABASE_CONFIG.items():\n",
                "    try:\n",
                "        print(f\"Creating engine for {db_key.upper()}...\")\n",
                "        engine = create_engine(config['uri'])\n",
                "\n",
                "        # Test connection\n",
                "        with engine.connect() as conn:\n",
                "            conn.execute(text(\"SELECT 1\"))\n",
                "\n",
                "        engines[db_key] = engine\n",
                "        print(f\"✓ {db_key.upper()} database engine created and tested successfully.\")\n",
                "\n",
                "    except OperationalError as e:\n",
                "        print(f\"✗ {db_key.upper()} database connection failed: {e}\")\n",
                "        raise\n",
                "    except SQLAlchemyError as e:\n",
                "        print(f\"✗ {db_key.upper()} database engine creation failed: {e}\")\n",
                "        raise\n",
                "    except Exception as e:\n",
                "        print(f\"✗ {db_key.upper()} unexpected error: {e}\")\n",
                "        raise\n",
                "\n",
                "print(\"=\"*50)\n",
                "print(\"All database engines ready for use.\")\n",
                "print(\"=\"*50)"
            ],
            "id": "9c23fc7ec571c42a",
            "outputs":
            [],
            "execution_count": null
        },
        {
            "metadata":
            {},
            "cell_type": "markdown",
            "source":
            [
                "---\n",
                "# Section 1: Data Extraction\n",
                "---"
            ],
            "id": "d3298d2a62222252"
        },
        {
            "metadata":
            {},
            "cell_type": "markdown",
            "source":
            [
                "## Query BAR Database\n",
                "\n",
                "Extract business filing data from the BAR database."
            ],
            "id": "1abb5c7f46de916f"
        },
        {
            "metadata":
            {},
            "cell_type": "code",
            "source":
            [
                "BAR_QUERY = \"\"\"\n",
                "SELECT DISTINCT ON (b.identifier)\n",
                "    CASE\n",
                "        WHEN b.identifier ~ '^\\\\d{7}$' THEN 'BC' || b.identifier\n",
                "        ELSE b.identifier\n",
                "    END AS identifier,\n",
                "    MAX(f.fiscal_year) OVER (PARTITION BY b.identifier) AS latest_fiscal_year,\n",
                "    MAX(f.filing_date) OVER (PARTITION BY b.identifier) AS last_ar_filing_date,\n",
                "    u.sub,\n",
                "    u.idp_userid,\n",
                "    f.payment_account\n",
                "FROM business b\n",
                "    JOIN filing f ON f.business_id = b.id\n",
                "    LEFT JOIN users u ON u.id = f.submitter_id\n",
                "WHERE f.status = 'COMPLETED'\n",
                "ORDER BY b.identifier, f.fiscal_year DESC;\n",
                "\"\"\"\n",
                "\n",
                "def query_bar_db(engine: Engine) -> pd.DataFrame:\n",
                "    \"\"\"Query BAR database for business filing data.\"\"\"\n",
                "    print(\"Starting BAR database query...\")\n",
                "    start_time = datetime.now()\n",
                "\n",
                "    with engine.connect() as conn:\n",
                "        df = pd.read_sql(text(BAR_QUERY), conn)\n",
                "\n",
                "    duration = (datetime.now() - start_time).total_seconds()\n",
                "\n",
                "    print(f\"BAR query completed in {duration:.2f} seconds\")\n",
                "    print(f\"Total records retrieved: {len(df):,}\")\n",
                "    print(f\"Records with null payment_account: {df['payment_account'].isna().sum():,}\")\n",
                "    print(f\"Unique payment_accounts: {df['payment_account'].nunique():,}\")\n",
                "\n",
                "    return df\n",
                "\n",
                "# Execute BAR query\n",
                "bar_df = query_bar_db(engines['bar'])\n",
                "\n",
                "# Preview data\n",
                "print(\"\\nSample BAR data:\")\n",
                "display(bar_df.head())\n",
                "print(f\"\\nColumn dtypes:\\n{bar_df.dtypes}\")"
            ],
            "id": "48467d0052099686",
            "outputs":
            [],
            "execution_count": null
        },
        {
            "metadata":
            {},
            "cell_type": "markdown",
            "source":
            [
                "## Query Auth Database for Mailing Address Status\n",
                "\n",
                "Determine which org/business combinations have complete mailing addresses.\n",
                "\n",
                "A mailing address is considered complete if ALL of the following fields are non-null:\n",
                "- `street`\n",
                "- `city`\n",
                "- `region`\n",
                "- `country`\n",
                "- `postal_code`"
            ],
            "id": "12840ad9947dd228"
        },
        {
            "metadata":
            {},
            "cell_type": "code",
            "source":
            [
                "AUTH_QUERY = \"\"\"\n",
                "SELECT DISTINCT\n",
                "    o.id AS org_id,\n",
                "    e.business_identifier,\n",
                "    CASE\n",
                "        WHEN c.city IS NOT NULL\n",
                "         AND c.country IS NOT NULL\n",
                "         AND c.street IS NOT NULL\n",
                "         AND c.region IS NOT NULL\n",
                "         AND c.postal_code IS NOT NULL\n",
                "        THEN TRUE\n",
                "        ELSE FALSE\n",
                "    END AS has_mailing_address\n",
                "FROM affiliations a\n",
                "JOIN orgs o ON a.org_id = o.id\n",
                "LEFT JOIN entities e ON a.entity_id = e.id\n",
                "LEFT JOIN contact_links cl ON o.id = cl.org_id\n",
                "LEFT JOIN contacts c ON cl.contact_id = c.id\n",
                "WHERE o.id = ANY(:org_ids)\n",
                ";\n",
                "\"\"\"\n",
                "\n",
                "def query_auth_mailing_addresses(engine: Engine, org_ids: list, chunk_size: int = 1000) -> pd.DataFrame:\n",
                "    \"\"\"\n",
                "    Query Auth database for mailing address status.\n",
                "\n",
                "    Args:\n",
                "        engine: SQLAlchemy engine for auth database\n",
                "        org_ids: List of org/account IDs to check\n",
                "        chunk_size: Number of org_ids per query batch\n",
                "\n",
                "    Returns:\n",
                "        DataFrame with org_id, business_identifier, has_mailing_address\n",
                "    \"\"\"\n",
                "    print(f\"Starting Auth database query for {len(org_ids):,} org IDs...\")\n",
                "    start_time = datetime.now()\n",
                "\n",
                "    # Remove nulls and duplicates\n",
                "    org_ids = [int(x) for x in org_ids if pd.notna(x)]\n",
                "    org_ids = list(set(org_ids))\n",
                "    print(f\"Unique non-null org IDs to query: {len(org_ids):,}\")\n",
                "\n",
                "    if not org_ids:\n",
                "        print(\"No valid org IDs to query!\")\n",
                "        return pd.DataFrame(columns=['org_id', 'business_identifier', 'has_mailing_address'])\n",
                "\n",
                "    # Process in chunks to avoid parameter limits\n",
                "    all_results = []\n",
                "    total_chunks = (len(org_ids) + chunk_size - 1) // chunk_size\n",
                "\n",
                "    with engine.connect() as conn:\n",
                "        for i in range(0, len(org_ids), chunk_size):\n",
                "            chunk = org_ids[i:i + chunk_size]\n",
                "            chunk_num = (i // chunk_size) + 1\n",
                "            print(f\"Processing chunk {chunk_num}/{total_chunks} ({len(chunk)} org IDs)...\")\n",
                "\n",
                "            result = pd.read_sql(\n",
                "                text(AUTH_QUERY),\n",
                "                conn,\n",
                "                params={'org_ids': chunk}\n",
                "            )\n",
                "            all_results.append(result)\n",
                "\n",
                "    # Combine all chunks\n",
                "    if all_results:\n",
                "        df = pd.concat(all_results, ignore_index=True)\n",
                "    else:\n",
                "        df = pd.DataFrame(columns=['org_id', 'business_identifier', 'has_mailing_address'])\n",
                "\n",
                "    duration = (datetime.now() - start_time).total_seconds()\n",
                "\n",
                "    print(f\"Auth query completed in {duration:.2f} seconds\")\n",
                "    print(f\"Total records retrieved: {len(df):,}\")\n",
                "\n",
                "    if len(df) > 0:\n",
                "        has_address_count = df['has_mailing_address'].sum()\n",
                "        print(f\"Records with mailing address: {has_address_count:,} ({100*has_address_count/len(df):.1f}%)\")\n",
                "        print(f\"Records without mailing address: {len(df) - has_address_count:,}\")\n",
                "\n",
                "    return df\n",
                "\n",
                "# Get list of org IDs from BAR data\n",
                "org_ids_to_query = bar_df['payment_account'].dropna().unique().tolist()\n",
                "print(f\"Extracted {len(org_ids_to_query):,} unique payment_account values from BAR data\")\n",
                "\n",
                "# Execute Auth query\n",
                "auth_df = query_auth_mailing_addresses(engines['auth'], org_ids_to_query)\n",
                "\n",
                "# Preview data\n",
                "print(\"\\nSample Auth data:\")\n",
                "display(auth_df.head())"
            ],
            "id": "f9876a762fa82401",
            "outputs":
            [],
            "execution_count": null
        },
        {
            "metadata":
            {},
            "cell_type": "markdown",
            "source":
            [
                "---\n",
                "# Section 2: Data Transformation\n",
                "---"
            ],
            "id": "d0719b0e79cab174"
        },
        {
            "metadata":
            {},
            "cell_type": "markdown",
            "source":
            [
                "## Merge BAR and Auth Data\n",
                "\n",
                "Merge the BAR filing data with Auth mailing address status.\n",
                "\n",
                "**Join logic:**\n",
                "- BAR `payment_account` = Auth `org_id`\n",
                "- BAR `identifier` (without 'BC' prefix) = Auth `business_identifier`\n",
                "\n",
                "**Note:** Records without a match in Auth will have `bar_account_has_mailing_address = False`"
            ],
            "id": "f467f1f74ca9a26a"
        },
        {
            "metadata":
            {},
            "cell_type": "code",
            "source":
            [
                "def merge_bar_auth_data(bar_df: pd.DataFrame, auth_df: pd.DataFrame) -> pd.DataFrame:\n",
                "    \"\"\"\n",
                "    Merge BAR and Auth data to create final bar_corps dataset.\n",
                "\n",
                "    Args:\n",
                "        bar_df: DataFrame from BAR database\n",
                "        auth_df: DataFrame from Auth database\n",
                "\n",
                "    Returns:\n",
                "        Merged DataFrame ready for loading into bar_corps table\n",
                "    \"\"\"\n",
                "    print(\"Starting data merge...\")\n",
                "    print(f\"BAR records: {len(bar_df):,}\")\n",
                "    print(f\"Auth records: {len(auth_df):,}\")\n",
                "\n",
                "    # Create a copy to avoid modifying original\n",
                "    bar_merged = bar_df.copy()\n",
                "\n",
                "    # Create identifier without 'BC' prefix for matching\n",
                "    # Auth business_identifier typically doesn't have the 'BC' prefix\n",
                "    bar_merged['identifier_for_match'] = bar_merged['identifier'].str.replace('^BC', '', regex=True)\n",
                "\n",
                "    # Ensure payment_account is numeric for joining\n",
                "    bar_merged['payment_account'] = pd.to_numeric(bar_merged['payment_account'], errors='coerce')\n",
                "\n",
                "    # Prepare auth data for merge\n",
                "    auth_for_merge = auth_df.copy()\n",
                "    auth_for_merge['org_id'] = pd.to_numeric(auth_for_merge['org_id'], errors='coerce')\n",
                "\n",
                "    # Aggregate auth data - if ANY record for org/business has mailing address, mark as True\n",
                "    # This handles cases where there might be multiple contact records\n",
                "    auth_agg = auth_for_merge.groupby(['org_id', 'business_identifier']).agg({\n",
                "        'has_mailing_address': 'max'  # True if any record has mailing address\n",
                "    }).reset_index()\n",
                "\n",
                "    print(f\"Auth records after aggregation: {len(auth_agg):,}\")\n",
                "\n",
                "    # Perform left join\n",
                "    merged_df = bar_merged.merge(\n",
                "        auth_agg,\n",
                "        left_on=['payment_account', 'identifier_for_match'],\n",
                "        right_on=['org_id', 'business_identifier'],\n",
                "        how='left'\n",
                "    )\n",
                "\n",
                "    # Fill nulls with False (no match = no mailing address on file)\n",
                "    merged_df['has_mailing_address'] = merged_df['has_mailing_address'].fillna(False)\n",
                "\n",
                "    # Rename to final column name\n",
                "    merged_df['bar_account_has_mailing_address'] = merged_df['has_mailing_address'].astype(bool)\n",
                "\n",
                "    # Select final columns matching bar_corps table schema\n",
                "    final_columns = [\n",
                "        'identifier',\n",
                "        'latest_fiscal_year',\n",
                "        'last_ar_filing_date',\n",
                "        'sub',\n",
                "        'idp_userid',\n",
                "        'payment_account',\n",
                "        'bar_account_has_mailing_address'\n",
                "    ]\n",
                "\n",
                "    result_df = merged_df[final_columns].copy()\n",
                "\n",
                "    # Log merge statistics\n",
                "    matched_count = merged_df['org_id'].notna().sum()\n",
                "    unmatched_count = len(merged_df) - matched_count\n",
                "    has_address_count = result_df['bar_account_has_mailing_address'].sum()\n",
                "\n",
                "    print(\"\")\n",
                "    print(\"=\" * 50)\n",
                "    print(\"MERGE STATISTICS\")\n",
                "    print(\"=\" * 50)\n",
                "    print(f\"Total records: {len(result_df):,}\")\n",
                "    print(f\"Matched with Auth: {matched_count:,} ({100*matched_count/len(result_df):.1f}%)\")\n",
                "    print(f\"Unmatched (no Auth record): {unmatched_count:,} ({100*unmatched_count/len(result_df):.1f}%)\")\n",
                "    print(f\"With mailing address: {has_address_count:,} ({100*has_address_count/len(result_df):.1f}%)\")\n",
                "    print(f\"Without mailing address: {len(result_df) - has_address_count:,}\")\n",
                "    print(\"=\" * 50)\n",
                "\n",
                "    return result_df\n",
                "\n",
                "# Perform merge\n",
                "final_df = merge_bar_auth_data(bar_df, auth_df)\n",
                "\n",
                "# Preview merged data\n",
                "print(\"\\nSample merged data:\")\n",
                "display(final_df.head(10))\n",
                "\n",
                "print(f\"\\nFinal DataFrame shape: {final_df.shape}\")\n",
                "print(f\"\\nColumn dtypes:\\n{final_df.dtypes}\")"
            ],
            "id": "4b9689d85bdaca6b",
            "outputs":
            [],
            "execution_count": null
        },
        {
            "metadata":
            {},
            "cell_type": "markdown",
            "source":
            [
                "## Data Validation\n",
                "\n",
                "Validate the merged data before loading."
            ],
            "id": "1a4577ed85ec2052"
        },
        {
            "metadata":
            {},
            "cell_type": "code",
            "source":
            [
                "def validate_data(df: pd.DataFrame) -> bool:\n",
                "    \"\"\"\n",
                "    Validate the merged DataFrame before loading.\n",
                "\n",
                "    Returns:\n",
                "        True if validation passes, False otherwise\n",
                "    \"\"\"\n",
                "    print(\"Running data validation...\")\n",
                "    issues = []\n",
                "\n",
                "    # Check for required columns\n",
                "    required_columns = [\n",
                "        'identifier', 'latest_fiscal_year', 'last_ar_filing_date',\n",
                "        'sub', 'idp_userid', 'payment_account', 'bar_account_has_mailing_address'\n",
                "    ]\n",
                "    missing_cols = set(required_columns) - set(df.columns)\n",
                "    if missing_cols:\n",
                "        issues.append(f\"Missing required columns: {missing_cols}\")\n",
                "\n",
                "    # Check identifier format\n",
                "    invalid_identifiers = df[~df['identifier'].str.match(r'^(BC\\d{7}|[A-Z]+\\d+)$', na=False)]\n",
                "    if len(invalid_identifiers) > 0:\n",
                "        print(f\"Records with potentially invalid identifier format: {len(invalid_identifiers)}\")\n",
                "        print(f\"Sample invalid identifiers: {invalid_identifiers['identifier'].head().tolist()}\")\n",
                "\n",
                "    # Check for duplicates\n",
                "    duplicate_count = df['identifier'].duplicated().sum()\n",
                "    if duplicate_count > 0:\n",
                "        issues.append(f\"Duplicate identifiers found: {duplicate_count}\")\n",
                "\n",
                "    # Check null counts in critical fields\n",
                "    null_identifiers = df['identifier'].isna().sum()\n",
                "    if null_identifiers > 0:\n",
                "        issues.append(f\"Null identifiers: {null_identifiers}\")\n",
                "\n",
                "    # Check boolean column\n",
                "    if df['bar_account_has_mailing_address'].dtype != bool:\n",
                "        print(f\"bar_account_has_mailing_address is {df['bar_account_has_mailing_address'].dtype}, expected bool\")\n",
                "\n",
                "    # Report results\n",
                "    if issues:\n",
                "        print(\"Validation FAILED with the following issues:\")\n",
                "        for issue in issues:\n",
                "            print(f\"  - {issue}\")\n",
                "        return False\n",
                "    else:\n",
                "        print(\"✓ Validation PASSED\")\n",
                "        return True\n",
                "\n",
                "# Run validation\n",
                "validation_passed = validate_data(final_df)\n",
                "\n",
                "if not validation_passed:\n",
                "    print(\"Validation failed - review issues before proceeding to load\")"
            ],
            "id": "58a38907389b494c",
            "outputs":
            [],
            "execution_count": null
        },
        {
            "metadata":
            {},
            "cell_type": "markdown",
            "source":
            [
                "---\n",
                "# Section 3: Data Loading\n",
                "---"
            ],
            "id": "23fa1e060b40acb8"
        },
        {
            "metadata":
            {},
            "cell_type": "markdown",
            "source":
            [
                "## Truncate and Load bar_corps Table\n",
                "\n",
                "⚠️ **WARNING**: This will truncate the existing `bar_corps` table!\n",
                "\n",
                "Operations:\n",
                "1. Truncate `bar_corps` table\n",
                "2. Insert merged data\n",
                "3. Verify row counts"
            ],
            "id": "d52fd92f2ad5db2b"
        },
        {
            "metadata":
            {},
            "cell_type": "code",
            "source":
            [
                "def load_bar_corps(engine: Engine, df: pd.DataFrame, chunk_size: int = 1000) -> int:\n",
                "    \"\"\"\n",
                "    Truncate and load data into bar_corps table.\n",
                "\n",
                "    Args:\n",
                "        engine: SQLAlchemy engine for colin_extract database\n",
                "        df: DataFrame to load\n",
                "        chunk_size: Rows per insert batch\n",
                "\n",
                "    Returns:\n",
                "        Number of rows inserted\n",
                "    \"\"\"\n",
                "    print(\"=\"*50)\n",
                "    print(\"STARTING DATA LOAD TO bar_corps\")\n",
                "    print(\"=\"*50)\n",
                "    start_time = datetime.now()\n",
                "\n",
                "    with engine.begin() as conn:  # Automatic transaction management\n",
                "        # Step 1: Get current row count\n",
                "        current_count = conn.execute(text(\"SELECT COUNT(*) FROM bar_corps\")).scalar()\n",
                "        print(f\"Current bar_corps row count: {current_count:,}\")\n",
                "\n",
                "        # Step 2: Truncate table\n",
                "        print(\"Truncating bar_corps table...\")\n",
                "        conn.execute(text(\"TRUNCATE TABLE bar_corps\"))\n",
                "        print(\"✓ Table truncated\")\n",
                "\n",
                "        # Step 3: Insert data\n",
                "        print(f\"Inserting {len(df):,} records (chunk_size={chunk_size})...\")\n",
                "\n",
                "        # Use pandas to_sql for efficient bulk insert\n",
                "        df.to_sql(\n",
                "            name='bar_corps',\n",
                "            con=conn,\n",
                "            if_exists='append',\n",
                "            index=False,\n",
                "            method='multi',\n",
                "            chunksize=chunk_size\n",
                "        )\n",
                "        print(\"✓ Data inserted\")\n",
                "\n",
                "        # Step 4: Verify row count\n",
                "        new_count = conn.execute(text(\"SELECT COUNT(*) FROM bar_corps\")).scalar()\n",
                "        print(f\"New bar_corps row count: {new_count:,}\")\n",
                "\n",
                "        if new_count != len(df):\n",
                "            print(f\"Row count mismatch! Expected {len(df):,}, got {new_count:,}\")\n",
                "        else:\n",
                "            print(\"✓ Row count verified\")\n",
                "\n",
                "    duration = (datetime.now() - start_time).total_seconds()\n",
                "    print(f\"Load completed in {duration:.2f} seconds\")\n",
                "    print(\"=\"*50)\n",
                "\n",
                "    return new_count\n",
                "\n",
                "# Execute load\n",
                "rows_loaded = load_bar_corps(engines['colin_extract'], final_df)\n",
                "print(f\"\\nTotal rows loaded: {rows_loaded:,}\")"
            ],
            "id": "aa380400c2fa3dfd",
            "outputs":
            [],
            "execution_count": null
        },
        {
            "metadata":
            {},
            "cell_type": "markdown",
            "source":
            [
                "## Verify Loaded Data\n",
                "\n",
                "Run verification queries against the loaded data."
            ],
            "id": "6d6320c2ba207c27"
        },
        {
            "metadata":
            {},
            "cell_type": "code",
            "source":
            [
                "def verify_loaded_data(engine: Engine) -> None:\n",
                "    \"\"\"\n",
                "    Run verification queries on the loaded bar_corps data.\n",
                "    \"\"\"\n",
                "    print(\"Running verification queries...\")\n",
                "\n",
                "    with engine.connect() as conn:\n",
                "        # Total count\n",
                "        total = conn.execute(text(\"SELECT COUNT(*) FROM bar_corps\")).scalar()\n",
                "        print(f\"Total records: {total:,}\")\n",
                "\n",
                "        # Count with mailing address\n",
                "        with_address = conn.execute(text(\n",
                "            \"SELECT COUNT(*) FROM bar_corps WHERE bar_account_has_mailing_address = TRUE\"\n",
                "        )).scalar()\n",
                "        print(f\"Records with mailing address: {with_address:,} ({100*with_address/total:.1f}%)\")\n",
                "\n",
                "        # Count by fiscal year\n",
                "        fiscal_year_df = pd.read_sql(text(\"\"\"\n",
                "            SELECT latest_fiscal_year, COUNT(*) as count\n",
                "            FROM bar_corps\n",
                "            WHERE latest_fiscal_year IS NOT NULL\n",
                "            GROUP BY latest_fiscal_year\n",
                "            ORDER BY latest_fiscal_year DESC\n",
                "            LIMIT 5\n",
                "        \"\"\"), conn)\n",
                "        print(f\"\\nTop 5 fiscal years:\\n{fiscal_year_df.to_string(index=False)}\")\n",
                "\n",
                "        # Sample records\n",
                "        sample_df = pd.read_sql(text(\"\"\"\n",
                "            SELECT * FROM bar_corps\n",
                "            ORDER BY last_ar_filing_date DESC NULLS LAST\n",
                "            LIMIT 5\n",
                "        \"\"\"), conn)\n",
                "        print(f\"\\nSample records (most recent filings):\")\n",
                "        display(sample_df)\n",
                "\n",
                "# Run verification\n",
                "verify_loaded_data(engines['colin_extract'])"
            ],
            "id": "b4c79cf900eda757",
            "outputs":
            [],
            "execution_count": null
        },
        {
            "metadata":
            {},
            "cell_type": "markdown",
            "source":
            [
                "---\n",
                "# Section 4: Materialized View Refresh (Optional)\n",
                "---"
            ],
            "id": "1a3f380e293ba730"
        },
        {
            "metadata":
            {},
            "cell_type": "markdown",
            "source":
            [
                "## Refresh mv_legacy_corps_data\n",
                "\n",
                "⚠️ **NOTE**: This may take several minutes depending on data volume.\n",
                "\n",
                "Only run this cell if you want to refresh the materialized view immediately."
            ],
            "id": "74ceb39db7a51fae"
        },
        {
            "metadata":
            {},
            "cell_type": "code",
            "source":
            [
                "def refresh_materialized_view(engine: Engine, view_name: str = 'mv_legacy_corps_data') -> None:\n",
                "    \"\"\"\n",
                "    Refresh the materialized view.\n",
                "\n",
                "    Args:\n",
                "        engine: SQLAlchemy engine for colin_extract database\n",
                "        view_name: Name of the materialized view to refresh\n",
                "    \"\"\"\n",
                "    print(f\"Starting refresh of {view_name}...\")\n",
                "    print(\"This may take several minutes...\")\n",
                "    start_time = datetime.now()\n",
                "\n",
                "    with engine.begin() as conn:\n",
                "        conn.execute(text(f\"REFRESH MATERIALIZED VIEW {view_name}\"))\n",
                "\n",
                "    duration = (datetime.now() - start_time).total_seconds()\n",
                "    print(f\"✓ Materialized view refreshed in {duration:.2f} seconds ({duration/60:.1f} minutes)\")\n",
                "\n",
                "refresh_materialized_view(engines['colin_extract'])"
            ],
            "id": "b160fb60506d632f",
            "outputs":
            [],
            "execution_count": null
        },
        {
            "metadata":
            {},
            "cell_type": "markdown",
            "source":
            [
                "## Verify Materialized View (After Refresh)\n",
                "\n",
                "Run this after refreshing the materialized view to verify the new column is populated."
            ],
            "id": "b509a17fb74abedc"
        },
        {
            "metadata":
            {},
            "cell_type": "code",
            "source":
            [
                "def verify_materialized_view(engine: Engine) -> None:\n",
                "    \"\"\"\n",
                "    Verify the materialized view has the data.\n",
                "    \"\"\"\n",
                "    print(\"Verifying mv_legacy_corps_data...\")\n",
                "\n",
                "    with engine.connect() as conn:\n",
                "        # Check data\n",
                "        stats = pd.read_sql(text(\"\"\"\n",
                "            SELECT\n",
                "                COUNT(*) as total,\n",
                "                SUM(CASE WHEN has_bar_filing THEN 1 ELSE 0 END) as with_bar_filing,\n",
                "                SUM(CASE WHEN bar_account_has_mailing_address THEN 1 ELSE 0 END) as with_mailing_address\n",
                "            FROM mv_legacy_corps_data\n",
                "        \"\"\"), conn)\n",
                "\n",
                "        print(f\"\\nMaterialized view statistics:\")\n",
                "        print(f\"  Total records: {stats['total'].iloc[0]:,}\")\n",
                "        print(f\"  With BAR filing: {stats['with_bar_filing'].iloc[0]:,}\")\n",
                "        print(f\"  With mailing address: {stats['with_mailing_address'].iloc[0]:,}\")\n",
                "\n",
                "verify_materialized_view(engines['colin_extract'])"
            ],
            "id": "c598ca18e8b29508",
            "outputs":
            [],
            "execution_count": null
        },
        {
            "metadata":
            {},
            "cell_type": "markdown",
            "source":
            [
                "---\n",
                "# Summary\n",
                "---"
            ],
            "id": "8a813b4e5350de5"
        },
        {
            "metadata":
            {},
            "cell_type": "code",
            "source":
            [
                "print(\"BAR CORPS DATA LOAD COMPLETE\")\n",
                "print(\"=\"*60)\n",
                "print(f\"BAR records processed: {len(bar_df):,}\")\n",
                "print(f\"Auth records retrieved: {len(auth_df):,}\")\n",
                "print(f\"Final records loaded: {len(final_df):,}\")\n",
                "print(f\"Records with mailing address: {final_df['bar_account_has_mailing_address'].sum():,}\")\n",
                "print(\"Refresh the materialized view\")\n",
                "print(\"Verify the materialized view\")\n",
                "print(\"=\"*60)"
            ],
            "id": "5411de45d8455164",
            "outputs":
            [],
            "execution_count": null
        }
    ],
    "metadata":
    {
        "kernelspec":
        {
            "name": "python3",
            "language": "python",
            "display_name": "Python 3 (ipykernel)"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}