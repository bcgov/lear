{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Migration Status Spreadsheet Notebook\n",
    "\n",
    "## Overview\n",
    "This notebook generates the data for the migration tracking spreadsheet.\n",
    "\n",
    "## What it does\n",
    "- Extracts migration data from COLIN Extract database\n",
    "- Retrieves filing information from LEAR database\n",
    "- Retrieves affiliation information from Auth database\n",
    "- Retrieves freeze status and early adopter information from COLIN database\n",
    "- Merges and exports data to Excel format\n",
    "- Composes a batch summary tab indicating migration overview of each batch\n",
    "\n",
    "## Output\n",
    "A formatted Excel spreadsheet tracking corporation migration status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install sqlalchemy>=2.0\n",
    "%pip install oracledb\n",
    "%pip install dotenv\n",
    "%pip install psycopg2-binary\n",
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Load Configuration\n",
    "\n",
    "Import required libraries and load environment variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oracledb\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError, OperationalError\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "COLUMN_NAMES = {\n",
    "    \"group\": \"Group\",\n",
    "    \"batch\": \"Batch\",\n",
    "    \"email\": \"Admin Email\",\n",
    "    \"corp_num\": \"Incorporation Number\",\n",
    "    \"corp_name\": \"Company Name\",\n",
    "    \"corp_type\": \"Type\",\n",
    "    \"frozen_in_colin\": \"Frozen in COLIN\",\n",
    "    \"banner_updated_in_colin\": \"COLIN Banner Updated\",\n",
    "    \"status\": \"Migration Status\",\n",
    "    \"date\": \"Migrated Date\",\n",
    "    \"affiliated\": \"Affiliated\",\n",
    "    \"account\": \"Account ID\",\n",
    "    \"account_name\": \"Account Name\",\n",
    "    \"filings\": \"Filings Done\",\n",
    "    \"filing_date\": \"Last Filing Date\"\n",
    "}\n",
    "\n",
    "SUMMARY_COL_NAMES = {\n",
    "    \"group_display_name\": \"Group\",\n",
    "    \"batch_display_name\": \"Batch\",\n",
    "    \"requested_date\": \"Requested Date\",\n",
    "    \"batch_status\": \"Migration Status\",\n",
    "    \"migrated_date\": \"Migrated Date\",\n",
    "    \"total_corps\": \"Migrated Businesses\",\n",
    "    \"notes\": \"Notes\"\n",
    "}\t\t\t\t\t\n",
    "\n",
    "TAB_NAMES = {\n",
    "    \"status\": \"Migration Status\",\n",
    "    \"summary\": \"Batch Summary\"\n",
    "}\n",
    "\n",
    "CONFIG = {\n",
    "    'batch_size': 5000,\n",
    "    'final_excel_fields': [\n",
    "        COLUMN_NAMES[\"group\"],\n",
    "        COLUMN_NAMES[\"batch\"],\n",
    "        COLUMN_NAMES[\"email\"],\n",
    "        COLUMN_NAMES[\"corp_num\"],\n",
    "        COLUMN_NAMES[\"corp_name\"],\n",
    "        COLUMN_NAMES[\"corp_type\"],\n",
    "        COLUMN_NAMES[\"frozen_in_colin\"],\n",
    "        COLUMN_NAMES[\"banner_updated_in_colin\"],\n",
    "        COLUMN_NAMES[\"status\"],\n",
    "        COLUMN_NAMES[\"date\"],\n",
    "        COLUMN_NAMES[\"affiliated\"],\n",
    "        COLUMN_NAMES[\"account\"],\n",
    "        COLUMN_NAMES['account_name'],\n",
    "        COLUMN_NAMES[\"filings\"],\n",
    "        COLUMN_NAMES[\"filing_date\"]\n",
    "    ],\n",
    "    'excel_export': {\n",
    "        'font_size': 14,\n",
    "        'max_column_width': 55,\n",
    "        'filled_color': 'FFCCCC',\n",
    "        'output_dir': os.getenv('EXPORT_OUTPUT_DIR')\n",
    "    }\n",
    "}\n",
    "\n",
    "# Configuration\n",
    "BATCH_SIZE = CONFIG['batch_size']\n",
    "FINAL_EXCEL_FIELDS = CONFIG['final_excel_fields']\n",
    "MIG_GROUP_IDS = [int(x.strip()) for x in os.getenv('MIG_GROUP_IDS').split(',') if x.strip().isdigit()]\n",
    "\n",
    "if not MIG_GROUP_IDS:\n",
    "    raise ValueError(\"MIG_GROUP_IDS is empty! Need at least one group id.\")\n",
    "\n",
    "mig_group_ids = ','.join(str(x) for x in MIG_GROUP_IDS)\n",
    "\n",
    "ORACLE_SCHEMA = os.getenv('DATABASE_COLIN_ORACLE_SCHEMA')\n",
    "\n",
    "if not ORACLE_SCHEMA:\n",
    "    raise ValueError(\"DATAVASE_COLIN_ORACLE_SCHEMA is not set.\")\n",
    "\n",
    "print(\"Libraries imported and configuration loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Setup\n",
    "\n",
    "Configure database connections using environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_CONFIG = {\n",
    "    'colin_extract': {\n",
    "        'username': os.getenv(\"DATABASE_COLIN_EXTRACT_USERNAME\"),\n",
    "        'password': os.getenv(\"DATABASE_COLIN_EXTRACT_PASSWORD\"),\n",
    "        'host': os.getenv(\"DATABASE_COLIN_EXTRACT_HOST\"),\n",
    "        'port': os.getenv(\"DATABASE_COLIN_EXTRACT_PORT\"),\n",
    "        'name': os.getenv(\"DATABASE_COLIN_EXTRACT_NAME\")\n",
    "    },\n",
    "    'lear': {\n",
    "        'username': os.getenv(\"DATABASE_LEAR_USERNAME\"),\n",
    "        'password': os.getenv(\"DATABASE_LEAR_PASSWORD\"),\n",
    "        'host': os.getenv(\"DATABASE_LEAR_HOST\"),\n",
    "        'port': os.getenv(\"DATABASE_LEAR_PORT\"),\n",
    "        'name': os.getenv(\"DATABASE_LEAR_NAME\")\n",
    "    },\n",
    "    'auth': {\n",
    "        'username': os.getenv(\"DATABASE_AUTH_USERNAME\"),\n",
    "        'password': os.getenv(\"DATABASE_AUTH_PASSWORD\"),\n",
    "        'host': os.getenv(\"DATABASE_AUTH_HOST\"),\n",
    "        'port': os.getenv(\"DATABASE_AUTH_PORT\"),\n",
    "        'name': os.getenv(\"DATABASE_AUTH_NAME\")\n",
    "    },\n",
    "    'colin_oracle': {\n",
    "        'username': os.getenv(\"DATABASE_COLIN_ORACLE_USERNAME\"),\n",
    "        'password': os.getenv(\"DATABASE_COLIN_ORACLE_PASSWORD\"),\n",
    "        'host': os.getenv(\"DATABASE_COLIN_ORACLE_HOST\"),\n",
    "        'port': os.getenv(\"DATABASE_COLIN_ORACLE_PORT\"),\n",
    "        'name': os.getenv(\"DATABASE_COLIN_ORACLE_NAME\"),\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "for db_key, db_config in DATABASE_CONFIG.items():\n",
    "    # Build Oracle URI\n",
    "    if db_key == 'colin_oracle':\n",
    "        uri = f\"oracle+oracledb://{db_config['username']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['name']}\"\n",
    "    # Build PostgreSQL URI\n",
    "    else:\n",
    "        uri = f\"postgresql://{db_config['username']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['name']}\"\n",
    "    DATABASE_CONFIG[db_key] = {'uri': uri}\n",
    "\n",
    "print(\"Database configurations successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Database Engines\n",
    "\n",
    "Create and test database connections for all configured databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracledb.init_oracle_client()\n",
    "\n",
    "engines = {}\n",
    "\n",
    "for db_key, config in DATABASE_CONFIG.items():\n",
    "    try:\n",
    "        engine = create_engine(config['uri'])\n",
    "        \n",
    "        # Test connection\n",
    "        with engine.connect() as conn:\n",
    "            if db_key =='colin_oracle':\n",
    "                conn.execute(text(\"SELECT 1 FROM DUAL\"))\n",
    "            else:\n",
    "                conn.execute(text(\"SELECT 1\"))\n",
    "        \n",
    "        engines[db_key] = engine\n",
    "        print(f\"{db_key.upper()} database engine created and tested successfully.\")\n",
    "    \n",
    "    except OperationalError as e:\n",
    "        print(f\"{db_key.upper()} database connection failed: {e}\")\n",
    "        raise\n",
    "    except SQLAlchemyError as e:\n",
    "        print(f\"{db_key.upper()} database engine creation failed: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"{db_key.upper()} unexpected error: {e}\")\n",
    "        raise\n",
    "\n",
    "ENGINE_NAMES = {engine: key for key, engine in engines.items()}\n",
    "\n",
    "print(\"All database engines ready for use.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Migration Data\n",
    "\n",
    "Query COLIN Extract database to get list of migrated corporations with their details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colin_extract_query = f\"\"\"\n",
    "SELECT\n",
    "    g.display_name AS \"{COLUMN_NAMES['group']}\",\n",
    "    b.display_name AS \"{COLUMN_NAMES['batch']}\",\n",
    "    mcb.corp_num AS \"{COLUMN_NAMES['corp_num']}\",\n",
    "    c.admin_email AS \"{COLUMN_NAMES['email']}\",\n",
    "    cn.corp_name AS \"{COLUMN_NAMES['corp_name']}\",\n",
    "    c.corp_type_cd AS \"{COLUMN_NAMES['corp_type']}\",\n",
    "    CASE\n",
    "        WHEN cp.processed_status = 'COMPLETED' THEN 'Migrated'\n",
    "        WHEN cp.processed_status = 'FAILED' THEN 'Failed'\n",
    "        WHEN cp.processed_status IS NULL THEN 'Pending'\n",
    "        ELSE 'Pending'\n",
    "    END AS \"{COLUMN_NAMES['status']}\",\n",
    "    cp.create_date::date AS \"{COLUMN_NAMES['date']}\"\n",
    "FROM\n",
    "    mig_corp_batch mcb\n",
    "    JOIN \n",
    "        mig_batch b ON mcb.mig_batch_id = b.id\n",
    "    JOIN \n",
    "        mig_group g ON b.mig_group_id = g.id\n",
    "    LEFT JOIN \n",
    "        corporation c ON mcb.corp_num = c.corp_num\n",
    "    LEFT JOIN \n",
    "        corp_processing cp ON mcb.corp_num = cp.corp_num\n",
    "    LEFT JOIN \n",
    "        corp_name cn ON c.corp_num = cn.corp_num \n",
    "            AND cn.corp_name_typ_cd IN ('CO', 'NB') \n",
    "            AND cn.end_event_id IS NULL\n",
    "WHERE\n",
    "    g.id IN ({mig_group_ids})\n",
    "    AND (\n",
    "        (cp.processed_status = 'COMPLETED' AND cp.environment = 'prod')\n",
    "        OR (cp.processed_status = 'FAILED' AND cp.environment = 'prod')\n",
    "        OR cp.processed_status IS NULL\n",
    "    )\n",
    "ORDER BY\n",
    "    g.display_name, \n",
    "    b.display_name,\n",
    "    CASE\n",
    "        WHEN cp.processed_status = 'COMPLETED' THEN 0\n",
    "        WHEN cp.processed_status = 'FAILED' THEN 1\n",
    "        ELSE 2\n",
    "    END, \n",
    "    cp.create_date DESC,\n",
    "    cn.corp_name;\n",
    "\"\"\"\n",
    "    \n",
    "try:\n",
    "    with engines['colin_extract'].connect() as conn:\n",
    "        colin_extract_df = pd.read_sql(colin_extract_query, conn)\n",
    "\n",
    "    if colin_extract_df.empty:\n",
    "        raise ValueError(\"COLIN Extract database query returned empty result\")\n",
    "    \n",
    "    print(f\"Fetched {len(colin_extract_df)} rows from COLIN Extract database.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error fetching data from COLIN Extract: {e}\")\n",
    "    raise\n",
    "\n",
    "# Display results\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(colin_extract_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Query Function\n",
    "A function to perform batch queries across multiple databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_query(query_sql, db_engine, batch_size, columns, is_colin_oracle=False):\n",
    "    # Get unique corporation numbers from the dataset\n",
    "    unique_corp_nums = colin_extract_df[COLUMN_NAMES['corp_num']].unique().tolist()\n",
    "\n",
    "    if is_colin_oracle:\n",
    "        # Convert corp_nums format if query in COLIN db\n",
    "        corp_num_mapping = {corp_num[2:] if corp_num.startswith('BC') else corp_num: corp_num\n",
    "                               for corp_num in unique_corp_nums}\n",
    "        unique_corp_nums = list(corp_num_mapping.keys())\n",
    "    else:\n",
    "        corp_num_mapping = None\n",
    "\n",
    "    corp_number_batches = [unique_corp_nums[i:i + batch_size] for i in range(0, len(unique_corp_nums), batch_size)]\n",
    "    db_name = ENGINE_NAMES.get(db_engine, \"Unknown database\")\n",
    "    batch_results = []\n",
    "    \n",
    "    # Process each batch of corporation numbers\n",
    "    for batch_idx, current_batch_corp_numbers in enumerate(corp_number_batches):\n",
    "        if not current_batch_corp_numbers:\n",
    "            continue\n",
    "        try:\n",
    "            with db_engine.connect() as conn:\n",
    "                if is_colin_oracle:\n",
    "                    corp_nums_str = ', '.join([f\"'{x}'\" for x in current_batch_corp_numbers])\n",
    "                    actual_query = query_sql.replace('{identifiers}', corp_nums_str)\n",
    "                    df = pd.read_sql(actual_query, conn)\n",
    "                else:\n",
    "                    df = pd.read_sql(query_sql, conn, params={'identifiers': current_batch_corp_numbers})\n",
    "            \n",
    "            # Store results from this batch\n",
    "            batch_results.append(df)\n",
    "            print(f\"{db_name} Batch {batch_idx+1}: {len(df)} records fetched\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"{db_name} Batch {batch_idx+1}/{len(corp_number_batches)} failed: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Process combined results\n",
    "    if batch_results:\n",
    "        combined_df = pd.concat(batch_results, ignore_index=True)\n",
    "\n",
    "        # Convert back to corp format starts with BC\n",
    "        if is_colin_oracle and corp_num_mapping:\n",
    "            combined_df[COLUMN_NAMES['corp_num']] = combined_df[COLUMN_NAMES['corp_num']].map(corp_num_mapping)\n",
    "\n",
    "        combined_df = combined_df.drop_duplicates(COLUMN_NAMES['corp_num'], keep='last')\n",
    "        print(f\"Total records fetched: {len(combined_df)}\")\n",
    "    else:\n",
    "        combined_df = pd.DataFrame(columns=columns)\n",
    "        print(f\"No records fetched\")\n",
    "    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Filing Data\n",
    "\n",
    "Retrieve and aggregate filing information from LEAR database for migrated corporations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lear_combined_query = f\"\"\"\n",
    "SELECT \n",
    "    b.id,\n",
    "    b.identifier AS \"{COLUMN_NAMES['corp_num']}\",\n",
    "    COALESCE(\n",
    "        STRING_AGG(f.filing_type, ', ' ORDER BY f.filing_type), \n",
    "        ''\n",
    "    ) AS \"{COLUMN_NAMES['filings']}\",\n",
    "    MAX(f.filing_date)::date AS \"{COLUMN_NAMES['filing_date']}\"\n",
    "FROM businesses b\n",
    "LEFT JOIN filings f ON b.id = f.business_id \n",
    "    AND f.source = 'LEAR' \n",
    "    AND f.status = 'COMPLETED'\n",
    "WHERE b.identifier = ANY(%(identifiers)s)\n",
    "GROUP BY b.id, b.identifier;\n",
    "\"\"\"\n",
    "\n",
    "lear_combined_df = batch_query(\n",
    "    query_sql=lear_combined_query,\n",
    "    db_engine=engines['lear'],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    columns=['id', COLUMN_NAMES['corp_num'], COLUMN_NAMES[\"filings\"], COLUMN_NAMES[\"filing_date\"]]\n",
    ")\n",
    "\n",
    "# Display results\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(lear_combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Affiliation Data\n",
    "\n",
    "Query the Auth database to get affiliation information, including whether corporations are affiliated and their account IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_query = f\"\"\"\n",
    "SELECT\n",
    "    e.business_identifier AS \"{COLUMN_NAMES['corp_num']}\",\n",
    "    CASE WHEN COUNT(a.id) > 0 THEN 'Y' ELSE 'N' END AS \"{COLUMN_NAMES['affiliated']}\",\n",
    "    COALESCE(\n",
    "        STRING_AGG(a.org_id::text, ', ' ORDER BY a.org_id),\n",
    "        ''\n",
    "    ) AS \"{COLUMN_NAMES['account']}\",\n",
    "    COALESCE(\n",
    "        STRING_AGG(o.name, ', ' ORDER BY a.org_id),\n",
    "        ''\n",
    "    ) AS \"{COLUMN_NAMES['account_name']}\"\n",
    "FROM\n",
    "    entities e\n",
    "LEFT JOIN\n",
    "    affiliations a ON e.id = a.entity_id\n",
    "LEFT JOIN\n",
    "    orgs o ON a.org_id = o.id\n",
    "WHERE\n",
    "    e.business_identifier = ANY(%(identifiers)s)\n",
    "GROUP BY\n",
    "    e.business_identifier\n",
    "\"\"\"\n",
    "\n",
    "auth_combined_df = batch_query(\n",
    "    query_sql=auth_query,\n",
    "    db_engine=engines['auth'],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    columns=[COLUMN_NAMES['corp_num'], COLUMN_NAMES['affiliated'], COLUMN_NAMES['account'], COLUMN_NAMES['account_name']]\n",
    ")\n",
    "\n",
    "# Data validation and processing for migrated corps\n",
    "migrated_corps = colin_extract_df[\n",
    "    colin_extract_df[COLUMN_NAMES['status']] == 'Migrated'\n",
    "][COLUMN_NAMES['corp_num']].tolist()\n",
    "\n",
    "auth_corps = auth_combined_df[COLUMN_NAMES['corp_num']].tolist()\n",
    "missing_from_auth = set(migrated_corps) - set(auth_corps)\n",
    "\n",
    "if missing_from_auth:\n",
    "    print(f\" {len(missing_from_auth)} migrated corporations missing from Auth database\")\n",
    "    \n",
    "    # Handle missing data in Auth\n",
    "    missing_records = []\n",
    "    for corp_num in missing_from_auth:\n",
    "        missing_records.append({\n",
    "            COLUMN_NAMES['corp_num']: corp_num,\n",
    "            COLUMN_NAMES['affiliated']: 'N',\n",
    "            COLUMN_NAMES['account']: '',\n",
    "            COLUMN_NAMES['account_name']: ''\n",
    "        })\n",
    "\n",
    "    if missing_records:\n",
    "        missing_auth_df = pd.DataFrame(missing_records)\n",
    "        auth_combined_df = pd.concat([auth_combined_df, missing_auth_df], ignore_index=True)\n",
    "\n",
    "# Display results\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(auth_combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get COLIN Data\n",
    "\n",
    "Retrieve corporation freeze status and early adopter information from Oracle COLIN database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colin_oracle_query = f\"\"\"\n",
    "SELECT\n",
    "    c.corp_num AS \"{COLUMN_NAMES['corp_num']}\",\n",
    "    CASE WHEN c.CORP_FROZEN_TYP_CD = 'C' THEN 'Y' ELSE 'N' END AS \"{COLUMN_NAMES['frozen_in_colin']}\",\n",
    "    CASE WHEN cea.corp_num IS NOT NULL THEN 'Y' ELSE 'N' END AS \"{COLUMN_NAMES['banner_updated_in_colin']}\"\n",
    "FROM\n",
    "    {ORACLE_SCHEMA}.CORPORATION c\n",
    "    LEFT JOIN {ORACLE_SCHEMA}.CORP_EARLY_ADOPTERS cea ON c.corp_num = cea.corp_num\n",
    "WHERE\n",
    "    c.corp_num IN ({{identifiers}})\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "colin_oracle_combined_df = batch_query(\n",
    "    query_sql=colin_oracle_query,\n",
    "    db_engine=engines['colin_oracle'],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    columns=[COLUMN_NAMES['corp_num'], COLUMN_NAMES['frozen_in_colin'], COLUMN_NAMES['banner_updated_in_colin']],\n",
    "    is_colin_oracle=True\n",
    ")\n",
    "\n",
    "# Display results\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(colin_oracle_combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Data\n",
    "\n",
    "Combine data from COLIN Extract, LEAR, and Auth databases into a merged dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    result = (colin_extract_df\n",
    "              .merge(lear_combined_df, \n",
    "                     on=COLUMN_NAMES['corp_num'], \n",
    "                     how='left')\n",
    "              .merge(auth_combined_df,\n",
    "                     on=COLUMN_NAMES['corp_num'],\n",
    "                     how='left')\n",
    "              .merge(colin_oracle_combined_df,\n",
    "                     on=COLUMN_NAMES['corp_num'],\n",
    "                     how='left') \n",
    "              )\n",
    "    \n",
    "    # Select final fields\n",
    "    merged_df = result[FINAL_EXCEL_FIELDS]\n",
    "    \n",
    "    print(f\"Data merged successfully: {len(merged_df)} rows\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error merging data: {e}\")\n",
    "\n",
    "# Display merged results\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Batch Summary Dataframe\n",
    "Query Colin Extract database to compose the Batch Summary tab.\n",
    "<br />Currently including 7 columns: Group, Batch, Requested Date, Migration Status, Migrated Date, Business Count, Batch Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_summary_query = f\"\"\"\n",
    "WITH batch_status AS (\n",
    "            SELECT \n",
    "                b.id as batch_id,\n",
    "                g.display_name as group_display_name,\n",
    "                b.display_name as batch_display_name,\n",
    "                b.requested_date,\n",
    "                b.migrated_date,\n",
    "                b.notes,\n",
    "                COUNT(DISTINCT mcb.corp_num) as total_corps,\n",
    "                COUNT(DISTINCT CASE \n",
    "                    WHEN cp.processed_status = 'COMPLETED' AND cp.environment = 'prod' \n",
    "                    THEN mcb.corp_num \n",
    "                END) as completed_corps\n",
    "            FROM mig_group g\n",
    "            JOIN mig_batch b ON g.id = b.mig_group_id\n",
    "            LEFT JOIN mig_corp_batch mcb ON b.id = mcb.mig_batch_id\n",
    "            LEFT JOIN corp_processing cp ON mcb.corp_num = cp.corp_num\n",
    "            WHERE g.id IN ({mig_group_ids})\n",
    "            GROUP BY b.id, g.display_name, b.display_name, b.requested_date, b.migrated_date\n",
    "        )\n",
    "        SELECT \n",
    "            group_display_name,\n",
    "            batch_display_name,\n",
    "            requested_date,\n",
    "            migrated_date,\n",
    "            total_corps,\n",
    "            notes,\n",
    "            CASE\n",
    "                WHEN total_corps = completed_corps THEN 'COMPLETED'\n",
    "                ELSE 'PENDING'\n",
    "            END as batch_status\n",
    "        FROM batch_status\n",
    "        ORDER BY group_display_name, batch_display_name\n",
    "\"\"\"\n",
    "try:\n",
    "    with engines['colin_extract'].connect() as conn:\n",
    "        batch_summary_df = pd.read_sql(batch_summary_query, conn)\n",
    "    \n",
    "    if batch_summary_df.empty:\n",
    "        raise ValueError(\"batch summary data query returned 0 result\")\n",
    "    \n",
    "    print(f\"Composed {len(batch_summary_df)} entries for batch summary\")\n",
    "\n",
    "    # formatting the dataframe with proper column order and column names\n",
    "    column_order = ['group_display_name', 'batch_display_name', 'requested_date', 'batch_status', 'migrated_date', 'total_corps', 'notes']\n",
    "    batch_summary_df = batch_summary_df[column_order]\n",
    "    batch_summary_df = batch_summary_df.rename(columns=SUMMARY_COL_NAMES)\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching data to compose batch summary: {e}\")\n",
    "    raise\n",
    "\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(batch_summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to Excel\n",
    "\n",
    "Generate formatted Excel file with the merged migration tracking data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define highlighting rules\n",
    "HIGHLIGHTING_RULES = [\n",
    "    {\n",
    "        'column_name': COLUMN_NAMES['affiliated'],\n",
    "        'condition_value': 'N',\n",
    "        'fill_color': CONFIG['excel_export']['filled_color']\n",
    "    },\n",
    "    {\n",
    "        'column_name': COLUMN_NAMES['banner_updated_in_colin'], \n",
    "        'condition_value': 'N',\n",
    "        'fill_color': CONFIG['excel_export']['filled_color']\n",
    "    },\n",
    "    {\n",
    "        'column_name': COLUMN_NAMES['status'],\n",
    "        'condition_value': 'Failed', \n",
    "        'fill_color': CONFIG['excel_export']['filled_color']\n",
    "    },\n",
    "    {\n",
    "        'column_name': COLUMN_NAMES['frozen_in_colin'],\n",
    "        'condition_value': 'N',\n",
    "        'fill_color': CONFIG['excel_export']['filled_color']\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl.styles import Font, PatternFill, Alignment\n",
    "\n",
    "def apply_cell_highlighting(worksheet, highlighting_rules):\n",
    "    \"\"\"\n",
    "    Apply conditional highlighting to worksheet cells based on rules.\n",
    "    \n",
    "    Args:\n",
    "        worksheet: The openpyxl worksheet\n",
    "        highlighting_rules: List of dicts with column_name, condition_value, fill_color\n",
    "    \n",
    "    Returns:\n",
    "        int: Total number of cells highlighted\n",
    "    \"\"\"\n",
    "    highlighted_count = 0\n",
    "    \n",
    "    # Find column indices for all highlighting rules\n",
    "    column_indices = {}\n",
    "    for col_idx, cell in enumerate(worksheet[1], 1):\n",
    "        for rule in highlighting_rules:\n",
    "            if cell.value == rule['column_name']:\n",
    "                column_indices[rule['column_name']] = col_idx\n",
    "                break\n",
    "    \n",
    "    # Apply highlighting based on rules\n",
    "    for row_num, row in enumerate(worksheet.iter_rows(), 1):\n",
    "        if row_num == 1:  # Skip header row\n",
    "            continue\n",
    "            \n",
    "        for col_idx, cell in enumerate(row, 1):\n",
    "            # Check each highlighting rule\n",
    "            for rule in highlighting_rules:\n",
    "                if col_idx == column_indices.get(rule['column_name']) and cell.value == rule['condition_value']:\n",
    "                    fill = PatternFill(start_color=rule['fill_color'], end_color=rule['fill_color'], fill_type='solid')\n",
    "                    cell.fill = fill\n",
    "                    highlighted_count += 1\n",
    "    \n",
    "    return highlighted_count\n",
    "\n",
    "\n",
    "def format_worksheet(worksheet) -> None:\n",
    "    \"\"\"Format the given worksheet.\"\"\"\n",
    "    \n",
    "    # Define display styles\n",
    "    header_font = Font(size=CONFIG['excel_export']['font_size'], bold=True)\n",
    "    normal_font = Font(size=CONFIG['excel_export']['font_size'])\n",
    "\n",
    "    # Apply cell highlighting\n",
    "    highlighted_count = apply_cell_highlighting(worksheet, HIGHLIGHTING_RULES)\n",
    "\n",
    "    # Format rows (excluding highlighting which is now handled separately)\n",
    "    for row_num, row in enumerate(worksheet.iter_rows(), 1):\n",
    "        for col_idx, cell in enumerate(row, 1):\n",
    "            if row_num == 1:\n",
    "                # Header row\n",
    "                cell.font = header_font\n",
    "            else:\n",
    "                # Data rows\n",
    "                cell.font = normal_font\n",
    "                cell.alignment = Alignment(horizontal='left')\n",
    "    \n",
    "    # Freeze header row\n",
    "    worksheet.freeze_panes = 'A2'\n",
    "\n",
    "    # Add filter\n",
    "    worksheet.auto_filter.ref = worksheet.dimensions\n",
    "    \n",
    "    # Add last updated at top right\n",
    "    last_updated = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    worksheet.cell(row=1, column=worksheet.max_column + 1, value=f\"Last Updated: {last_updated}\").font = normal_font\n",
    "    \n",
    "    # Adjust column width\n",
    "    for column in worksheet.columns:\n",
    "        max_length = 0\n",
    "        column_letter = column[0].column_letter\n",
    "        worksheet.column_dimensions[column_letter].alignment = Alignment(horizontal='left')\n",
    "\n",
    "        for cell in column:\n",
    "            try:\n",
    "                if cell.value and len(str(cell.value)) > max_length:\n",
    "                    max_length = len(str(cell.value))\n",
    "            except (TypeError, AttributeError):\n",
    "                continue\n",
    "        \n",
    "        adjusted_width = min(max_length + 10, CONFIG['excel_export']['max_column_width'])\n",
    "        worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "    # Print highlighting summary\n",
    "    rule_names = [rule['column_name'] for rule in HIGHLIGHTING_RULES]\n",
    "    print(f\"In {worksheet.title} tab:\\n Red highlighting applied to {highlighted_count} cells across columns: {', '.join(rule_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if merged_df.empty:\n",
    "    raise ValueError(\"Data is empty, cannot export\")\n",
    "\n",
    "if batch_summary_df.empty:\n",
    "    raise ValueError(\"Batch Summary dataframe is empty, nothing to export\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(CONFIG['excel_export']['output_dir'], exist_ok=True)\n",
    "\n",
    "# Generate filename\n",
    "# if reading an existing Excel file and update data\n",
    "read_path = os.getenv('READ_FILE_DIR')\n",
    "read_file = os.getenv('EXCEL_FILE_READ')\n",
    "writer_mode = 'create'\n",
    "\n",
    "if not read_file or not read_path:\n",
    "    excel_filename = f\"migration_status.xlsx\"\n",
    "    excel_filepath = os.path.join(CONFIG['excel_export']['output_dir'], excel_filename)\n",
    "    print(\"No file to read. Or reading file path not configured. Creating migration tracking spreadsheet.\")\n",
    "elif os.path.exists(excel_filepath := os.path.join(read_path, read_file)):\n",
    "    writer_mode = 'update'\n",
    "    print(\"Updating migration tracking spreadsheet.\")\n",
    "else:\n",
    "    raise FileExistsError(\"Configured file reading path, but file doesn't exist.\")\n",
    "\n",
    "try:\n",
    "    writer_kwargs = {'engine': 'openpyxl'}\n",
    "    if writer_mode != 'create':\n",
    "        writer_kwargs.update({'mode': 'a', 'if_sheet_exists': 'replace'})\n",
    "    \n",
    "    with pd.ExcelWriter(excel_filepath, **writer_kwargs) as writer:\n",
    "        print(f\"Mode: {writer_mode}\")\n",
    "        # Export Batch Summary tab data\n",
    "        batch_summary_df.to_excel(writer, sheet_name=TAB_NAMES['summary'], index=False)\n",
    "        b_sum_worksheet = writer.sheets[TAB_NAMES['summary']]\n",
    "        format_worksheet(b_sum_worksheet)\n",
    "\n",
    "        # Export Migration Status tab data\n",
    "        merged_df.to_excel(writer, sheet_name=TAB_NAMES['status'], index=False)\n",
    "        mig_status_worksheet = writer.sheets[TAB_NAMES['status']]\n",
    "        format_worksheet(mig_status_worksheet)\n",
    "\n",
    "    print(f\"Excel export successful: {excel_filepath}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Excel export failed: {e}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
