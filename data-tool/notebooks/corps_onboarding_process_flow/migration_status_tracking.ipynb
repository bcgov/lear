{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Migration Status Spreadsheet Notebook\n",
    "\n",
    "## Overview\n",
    "This notebook generates the data for the migration tracking spreadsheet.\n",
    "\n",
    "## What it does\n",
    "- Extracts migration data from COLIN Extract database\n",
    "- Retrieves filing information from LEAR database\n",
    "- Retrieves affiliation information from Auth database\n",
    "- Merges and exports data to Excel format\n",
    "\n",
    "## Output\n",
    "A formatted Excel spreadsheet tracking corporation migration status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install sqlalchemy\n",
    "%pip install dotenv\n",
    "%pip install psycopg2-binary\n",
    "%pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Load Configuration\n",
    "\n",
    "Import required libraries and load environment variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError, OperationalError\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "COLUMN_NAMES = {\n",
    "    \"group\": \"Group\",\n",
    "    \"batch\": \"Batch\",\n",
    "    \"email\": \"Admin Email\",\n",
    "    \"corp_num\": \"Incorporation Number\",\n",
    "    \"corp_name\": \"Company Name\",\n",
    "    \"corp_type\": \"Type\",\n",
    "    \"status\": \"Migration Status\",\n",
    "    \"date\": \"Migrated Date\",\n",
    "    \"affiliated\": \"Affiliated\",\n",
    "    \"account\": \"Account ID\",\n",
    "    \"filings\": \"Filings Done\",\n",
    "    \"filing_date\": \"Last Filing Date\"\n",
    "}\n",
    "\n",
    "SUMMARY_COL_NAMES = {\n",
    "    \"group_display_name\": \"Group\",\n",
    "    \"batch_display_name\": \"Batch\",\n",
    "    \"requested_date\": \"Requested Date\",\n",
    "    \"batch_status\": \"Migration Status\",\n",
    "    \"migrated_date\": \"Migrated Date\",\n",
    "    \"total_corps\": \"Business Count\",\n",
    "    \"notes\": \"Batch Notes\"\n",
    "}\t\t\t\t\t\n",
    "\n",
    "TAB_NAMES = {\n",
    "    \"status\": \"Migration Status\",\n",
    "    \"summary\": \"Batch Summary\"\n",
    "}\n",
    "\n",
    "CONFIG = {\n",
    "    'batch_size': 5000,\n",
    "    'final_excel_fields': [\n",
    "        COLUMN_NAMES[\"group\"],\n",
    "        COLUMN_NAMES[\"batch\"],\n",
    "        COLUMN_NAMES[\"email\"],\n",
    "        COLUMN_NAMES[\"corp_num\"],\n",
    "        COLUMN_NAMES[\"corp_name\"],\n",
    "        COLUMN_NAMES[\"corp_type\"],\n",
    "        COLUMN_NAMES[\"status\"],\n",
    "        COLUMN_NAMES[\"date\"],\n",
    "        COLUMN_NAMES[\"affiliated\"],\n",
    "        COLUMN_NAMES[\"account\"],\n",
    "        COLUMN_NAMES[\"filings\"],\n",
    "        COLUMN_NAMES[\"filing_date\"]\n",
    "    ],\n",
    "    'excel_export': {\n",
    "        'font_size': 12,\n",
    "        'max_column_width': 50,\n",
    "        'output_dir': os.getenv('EXPORT_OUTPUT_DIR')\n",
    "    }\n",
    "}\n",
    "\n",
    "# Configuration\n",
    "BATCH_SIZE = CONFIG['batch_size']\n",
    "FINAL_EXCEL_FIELDS = CONFIG['final_excel_fields']\n",
    "MIG_GROUP_IDS = [int(x.strip()) for x in os.getenv('MIG_GROUP_IDS').split(',') if x.strip().isdigit()]\n",
    "\n",
    "if not MIG_GROUP_IDS:\n",
    "    raise ValueError(\"MIG_GROUP_IDS is empty! Need at least one group id.\")\n",
    "\n",
    "mig_group_ids = ','.join(str(x) for x in MIG_GROUP_IDS)\n",
    "\n",
    "print(\"Libraries imported and configuration loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Setup\n",
    "\n",
    "Configure database connections using environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_CONFIG = {\n",
    "    'colin_extract': {\n",
    "        'username': os.getenv(\"DATABASE_COLIN_EXTRACT_USERNAME\"),\n",
    "        'password': os.getenv(\"DATABASE_COLIN_EXTRACT_PASSWORD\"),\n",
    "        'host': os.getenv(\"DATABASE_COLIN_EXTRACT_HOST\"),\n",
    "        'port': os.getenv(\"DATABASE_COLIN_EXTRACT_PORT\"),\n",
    "        'name': os.getenv(\"DATABASE_COLIN_EXTRACT_NAME\")\n",
    "    },\n",
    "    'lear': {\n",
    "        'username': os.getenv(\"DATABASE_LEAR_USERNAME\"),\n",
    "        'password': os.getenv(\"DATABASE_LEAR_PASSWORD\"),\n",
    "        'host': os.getenv(\"DATABASE_LEAR_HOST\"),\n",
    "        'port': os.getenv(\"DATABASE_LEAR_PORT\"),\n",
    "        'name': os.getenv(\"DATABASE_LEAR_NAME\")\n",
    "    },\n",
    "    'auth': {\n",
    "        'username': os.getenv(\"DATABASE_AUTH_USERNAME\"),\n",
    "        'password': os.getenv(\"DATABASE_AUTH_PASSWORD\"),\n",
    "        'host': os.getenv(\"DATABASE_AUTH_HOST\"),\n",
    "        'port': os.getenv(\"DATABASE_AUTH_PORT\"),\n",
    "        'name': os.getenv(\"DATABASE_AUTH_NAME\")\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "for db_key, db_config in DATABASE_CONFIG.items():\n",
    "    # Build URI\n",
    "    uri = f\"postgresql://{db_config['username']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['name']}\"\n",
    "    DATABASE_CONFIG[db_key] = {'uri': uri}\n",
    "\n",
    "print(\"Database configurations successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Database Engines\n",
    "\n",
    "Create and test database connections for all configured databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engines = {}\n",
    "\n",
    "for db_key, config in DATABASE_CONFIG.items():\n",
    "    try:\n",
    "        engine = create_engine(config['uri'])\n",
    "        \n",
    "        # Test connection\n",
    "        with engine.connect() as conn:\n",
    "            conn.execute(text(\"SELECT 1\"))\n",
    "        \n",
    "        engines[db_key] = engine\n",
    "        print(f\"{db_key.upper()} database engine created and tested successfully.\")\n",
    "    \n",
    "    except OperationalError as e:\n",
    "        print(f\"{db_key.upper()} database connection failed: {e}\")\n",
    "        raise\n",
    "    except SQLAlchemyError as e:\n",
    "        print(f\"{db_key.upper()} database engine creation failed: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"{db_key.upper()} unexpected error: {e}\")\n",
    "        raise\n",
    "\n",
    "ENGINE_NAMES = {engine: key for key, engine in engines.items()}\n",
    "\n",
    "print(\"All database engines ready for use.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Migration Data\n",
    "\n",
    "Query COLIN Extract database to get list of migrated corporations with their details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colin_extract_query = f\"\"\"\n",
    "SELECT\n",
    "    g.display_name AS \"{COLUMN_NAMES['group']}\",\n",
    "    b.display_name AS \"{COLUMN_NAMES['batch']}\",\n",
    "    mcb.corp_num AS \"{COLUMN_NAMES['corp_num']}\",\n",
    "    c.admin_email AS \"{COLUMN_NAMES['email']}\",\n",
    "    cn.corp_name AS \"{COLUMN_NAMES['corp_name']}\",\n",
    "    c.corp_type_cd AS \"{COLUMN_NAMES['corp_type']}\",\n",
    "    CASE\n",
    "        WHEN cp.processed_status = 'COMPLETED' THEN 'Migrated'\n",
    "        WHEN cp.processed_status IS NULL THEN 'Pending'\n",
    "    END AS \"{COLUMN_NAMES['status']}\",\n",
    "    cp.create_date::date AS \"{COLUMN_NAMES['date']}\"\n",
    "FROM\n",
    "    mig_corp_batch mcb\n",
    "    JOIN \n",
    "        mig_batch b ON mcb.mig_batch_id = b.id\n",
    "    JOIN \n",
    "        mig_group g ON b.mig_group_id = g.id\n",
    "    LEFT JOIN \n",
    "        corporation c ON mcb.corp_num = c.corp_num\n",
    "    LEFT JOIN \n",
    "        corp_processing cp ON mcb.corp_num = cp.corp_num\n",
    "    LEFT JOIN \n",
    "        corp_name cn ON c.corp_num = cn.corp_num \n",
    "            AND cn.corp_name_typ_cd IN ('CO', 'NB') \n",
    "            AND cn.end_event_id IS NULL\n",
    "WHERE\n",
    "    g.id IN ({mig_group_ids})\n",
    "    AND (\n",
    "        (cp.processed_status = 'COMPLETED' AND cp.environment = 'prod')\n",
    "        OR cp.processed_status IS NULL\n",
    "    )\n",
    "ORDER BY\n",
    "    g.display_name, \n",
    "    b.display_name,\n",
    "    CASE\n",
    "        WHEN cp.processed_status = 'COMPLETED' THEN 0\n",
    "        ELSE 1\n",
    "    END, \n",
    "    cp.create_date DESC,\n",
    "    cn.corp_name;\n",
    "\"\"\"\n",
    "    \n",
    "try:\n",
    "    with engines['colin_extract'].connect() as conn:\n",
    "        colin_extract_df = pd.read_sql(colin_extract_query, conn)\n",
    "\n",
    "    if colin_extract_df.empty:\n",
    "        raise ValueError(\"COLIN Extract database query returned empty result\")\n",
    "    \n",
    "    print(f\"Fetched {len(colin_extract_df)} rows from COLIN Extract database.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error fetching data from COLIN Extract: {e}\")\n",
    "    raise\n",
    "\n",
    "# Display results\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(colin_extract_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Query Function\n",
    "A function to perform batch queries across multiple databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_query(query_sql, db_engine, batch_size, columns):\n",
    "    # Get unique corporation numbers from the dataset\n",
    "    unique_corp_nums = colin_extract_df[COLUMN_NAMES['corp_num']].unique().tolist()\n",
    "    corp_number_batches = [unique_corp_nums[i:i + batch_size] for i in range(0, len(unique_corp_nums), batch_size)]\n",
    "    db_name = ENGINE_NAMES.get(db_engine, \"Unknown database\")\n",
    "    batch_results = []\n",
    "    \n",
    "    # Process each batch of corporation numbers\n",
    "    for batch_idx, current_batch_corp_numbers in enumerate(corp_number_batches):\n",
    "        if not current_batch_corp_numbers:\n",
    "            continue\n",
    "        try:\n",
    "            with db_engine.connect() as conn:\n",
    "                df = pd.read_sql(query_sql, conn, params={'identifiers': current_batch_corp_numbers})\n",
    "            \n",
    "            # Store results from this batch\n",
    "            batch_results.append(df)\n",
    "            print(f\"{db_name} Batch {batch_idx+1}: {len(df)} records fetched\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"{db_name} Batch {batch_idx+1}/{len(corp_number_batches)} failed: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Process combined results\n",
    "    if batch_results:\n",
    "        combined_df = pd.concat(batch_results, ignore_index=True)\n",
    "        combined_df = combined_df.drop_duplicates(COLUMN_NAMES['corp_num'], keep='last')\n",
    "        print(f\"Total records fetched: {len(combined_df)}\")\n",
    "    else:\n",
    "        combined_df = pd.DataFrame(columns=columns)\n",
    "        print(f\"No records fetched\")\n",
    "    \n",
    "    return combined_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Filing Data\n",
    "\n",
    "Retrieve and aggregate filing information from LEAR database for migrated corporations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lear_combined_query = f\"\"\"\n",
    "SELECT \n",
    "    b.id,\n",
    "    b.identifier AS \"{COLUMN_NAMES['corp_num']}\",\n",
    "    COALESCE(\n",
    "        STRING_AGG(f.filing_type, ', ' ORDER BY f.filing_type), \n",
    "        ''\n",
    "    ) AS \"{COLUMN_NAMES['filings']}\",\n",
    "    MAX(f.filing_date)::date AS \"{COLUMN_NAMES['filing_date']}\"\n",
    "FROM businesses b\n",
    "LEFT JOIN filings f ON b.id = f.business_id \n",
    "    AND f.source = 'LEAR' \n",
    "    AND f.status = 'COMPLETED'\n",
    "WHERE b.identifier = ANY(%(identifiers)s)\n",
    "GROUP BY b.id, b.identifier;\n",
    "\"\"\"\n",
    "\n",
    "lear_combined_df = batch_query(\n",
    "    query_sql=lear_combined_query,\n",
    "    db_engine=engines['lear'],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    columns=['id', COLUMN_NAMES['corp_num'], COLUMN_NAMES[\"filings\"], COLUMN_NAMES[\"filing_date\"]]\n",
    ")\n",
    "\n",
    "# Display results\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(lear_combined_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Affiliation Data\n",
    "\n",
    "Query the Auth database to get affiliation information, including whether corporations are affiliated and their account IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_query = f\"\"\"\n",
    "SELECT\n",
    "    e.business_identifier AS \"{COLUMN_NAMES['corp_num']}\",\n",
    "    CASE WHEN COUNT(a.id) > 0 THEN 'Y' ELSE 'N' END AS \"{COLUMN_NAMES['affiliated']}\",\n",
    "    COALESCE(\n",
    "        STRING_AGG(a.org_id::text, ', ' ORDER BY a.org_id),\n",
    "        ''\n",
    "    ) AS \"{COLUMN_NAMES['account']}\"\n",
    "FROM\n",
    "    entities e\n",
    "LEFT JOIN\n",
    "    affiliations a ON e.id = a.entity_id\n",
    "WHERE\n",
    "    e.business_identifier = ANY(%(identifiers)s)\n",
    "GROUP BY\n",
    "    e.business_identifier\n",
    "\"\"\"\n",
    "\n",
    "auth_combined_df = batch_query(\n",
    "    query_sql=auth_query,\n",
    "    db_engine=engines['auth'],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    columns=[COLUMN_NAMES['corp_num'], COLUMN_NAMES['affiliated'], COLUMN_NAMES['account']]\n",
    ")\n",
    "\n",
    "# Display results\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(auth_combined_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Data\n",
    "\n",
    "Combine data from COLIN Extract, LEAR, and Auth databases into a merged dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    result = (colin_extract_df\n",
    "              .merge(lear_combined_df, \n",
    "                     on=COLUMN_NAMES['corp_num'], \n",
    "                     how='left')\n",
    "              .merge(auth_combined_df,\n",
    "                     on=COLUMN_NAMES['corp_num'],\n",
    "                     how='left') \n",
    "              )\n",
    "    \n",
    "    # Select final fields\n",
    "    merged_df = result[FINAL_EXCEL_FIELDS]\n",
    "    \n",
    "    print(f\"Data merged successfully: {len(merged_df)} rows\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error merging data: {e}\")\n",
    "\n",
    "# Display merged results\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(merged_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Batch Summary Dataframe\n",
    "Query Colin Extract database to compose the Batch Summary tab.\n",
    "<br />Currently including 7 columns: Group, Batch, Requested Date, Migration Status, Migrated Date, Business Count, Batch Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_summary_query = f\"\"\"\n",
    "WITH batch_status AS (\n",
    "            SELECT \n",
    "                b.id as batch_id,\n",
    "                g.display_name as group_display_name,\n",
    "                b.display_name as batch_display_name,\n",
    "                b.requested_date,\n",
    "                b.migrated_date,\n",
    "                b.notes,\n",
    "                COUNT(DISTINCT mcb.corp_num) as total_corps,\n",
    "                COUNT(DISTINCT CASE \n",
    "                    WHEN cp.processed_status = 'COMPLETED' AND cp.environment = 'prod' \n",
    "                    THEN mcb.corp_num \n",
    "                END) as completed_corps\n",
    "            FROM mig_group g\n",
    "            JOIN mig_batch b ON g.id = b.mig_group_id\n",
    "            LEFT JOIN mig_corp_batch mcb ON b.id = mcb.mig_batch_id\n",
    "            LEFT JOIN corp_processing cp ON mcb.corp_num = cp.corp_num\n",
    "            WHERE g.id IN ({mig_group_ids})\n",
    "            GROUP BY b.id, g.display_name, b.display_name, b.requested_date, b.migrated_date\n",
    "        )\n",
    "        SELECT \n",
    "            group_display_name,\n",
    "            batch_display_name,\n",
    "            requested_date,\n",
    "            migrated_date,\n",
    "            total_corps,\n",
    "            notes,\n",
    "            CASE\n",
    "                WHEN total_corps = completed_corps THEN 'COMPLETED'\n",
    "                ELSE 'PENDING'\n",
    "            END as batch_status\n",
    "        FROM batch_status\n",
    "        ORDER BY group_display_name, batch_display_name\n",
    "\"\"\"\n",
    "try:\n",
    "    with engines['colin_extract'].connect() as conn:\n",
    "        batch_summary_df = pd.read_sql(batch_summary_query, conn)\n",
    "    \n",
    "    if batch_summary_df.empty:\n",
    "        raise ValueError(\"batch summary data query returned 0 result\")\n",
    "    \n",
    "    print(f\"Composed {len(batch_summary_df)} entries for batch summary\")\n",
    "\n",
    "    # formatting the dataframe with proper column order and column names\n",
    "    column_order = ['group_display_name', 'batch_display_name', 'requested_date', 'batch_status', 'migrated_date', 'total_corps', 'notes']\n",
    "    batch_summary_df = batch_summary_df[column_order]\n",
    "    batch_summary_df = batch_summary_df.rename(columns=SUMMARY_COL_NAMES)\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching data to compose batch summary: {e}\")\n",
    "    raise\n",
    "\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(batch_summary_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to Excel\n",
    "\n",
    "Generate formatted Excel file with the merged migration tracking data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl.styles import Font\n",
    "\n",
    "def format_worksheet(worksheet) -> None:\n",
    "    \"\"\"Format the given worksheet.\"\"\"\n",
    "    # Adjust format\n",
    "    for row_num, row in enumerate(worksheet.iter_rows(), 1):\n",
    "        for cell in row:\n",
    "            cell.font = Font(\n",
    "                size=CONFIG['excel_export']['font_size'], \n",
    "                bold=(row_num == 1)\n",
    "            )\n",
    "\n",
    "    # Freeze header row\n",
    "    worksheet.freeze_panes = 'A2'\n",
    "    \n",
    "    # Adjust column width\n",
    "    for column in worksheet.columns:\n",
    "        max_length = 0\n",
    "        column_letter = column[0].column_letter\n",
    "        \n",
    "        for cell in column:\n",
    "            try:\n",
    "                if cell.value and len(str(cell.value)) > max_length:\n",
    "                    max_length = len(str(cell.value))\n",
    "            except (TypeError, AttributeError):\n",
    "                continue\n",
    "        \n",
    "        adjusted_width = min(max_length + 5, CONFIG['excel_export']['max_column_width'])\n",
    "        worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "\n",
    "if merged_df.empty:\n",
    "    raise ValueError(\"Migration Status dataframe is empty, cannot export\")\n",
    "\n",
    "if batch_summary_df.empty:\n",
    "    raise ValueError(\"Batch Summary dataframe is empty, nothing to export\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(CONFIG['excel_export']['output_dir'], exist_ok=True)\n",
    "\n",
    "# Generate filename\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "excel_filename = f\"migration_status_{timestamp}.xlsx\"\n",
    "excel_filepath = os.path.join(CONFIG['excel_export']['output_dir'], excel_filename)\n",
    "\n",
    "# Export dataframes to two tabs in the Excel file\n",
    "try:\n",
    "    with pd.ExcelWriter(excel_filepath, engine='openpyxl') as writer:\n",
    "        # Export Migration Status tab data\n",
    "        merged_df.to_excel(writer, sheet_name=TAB_NAMES['status'], index=False)\n",
    "        mig_status_worksheet = writer.sheets[TAB_NAMES['status']]\n",
    "        format_worksheet(mig_status_worksheet)\n",
    "\n",
    "        # Export Batch Summary tab data\n",
    "        batch_summary_df.to_excel(writer, sheet_name=TAB_NAMES['summary'], index=False)\n",
    "        b_sum_worksheet = writer.sheets[TAB_NAMES['summary']]\n",
    "        format_worksheet(b_sum_worksheet)       \n",
    "\n",
    "    print(f\"Excel export successful: {excel_filename}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Excel export failed: {e}\")\n",
    "    raise\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
