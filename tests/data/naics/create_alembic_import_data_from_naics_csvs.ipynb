{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Bulk Import Output for Alembic Scripts from StatsCan NAICS Data\n",
    "This notebook contains code snippets to generate output for alembic scripts.\n",
    "\n",
    "The output generation by default generates data for production purposes.  But if `generate_subset_of_naics_data` is set to `True`, a subset of the codes can be generated for test purposes.  This option was added as unit tests were taking too long to load the production set of naics structures/codes and naics elements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run /workspaces/lear/tests/data/common/naics_utils.ipynb\n",
    "\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import chardet\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naics_structure_filename = '../data/naics/naics-scian-2017-structure-v3-eng.csv'\n",
    "naics_element_filename = '../data/naics/naics-scian-2017-element-v3-eng.csv'\n",
    "naics_year = 2017\n",
    "naics_version = 3\n",
    "# set to generate_subset_of_naics_data to True if need to generate a subset of NAICS data by filtering on codes.\n",
    "# This is needed so that lear services/jobs/apis are able to apply alembic migrations scripts quickly when running unit tests.\n",
    "# Leave as False if all NAICS data needs to be generated.\n",
    "generate_subset_of_naics_data = False\n",
    "# only used if generate_subset_of_naics_data is set to True to filter on which codes to generate output for\n",
    "# for example, codes values of ['112320', '311351', '311911', '311920', '327410', '333248', '335223', '413130', '413190'] contain data relevant to the search term 'roast'\n",
    "codes_to_add = ['112320', '311351', '311911', '311920', '327410', '333248', '335223', '413130', '413190']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dict from NAICS structure data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_encoding_result = None\n",
    "with open(naics_structure_filename, 'rb') as rawdata:\n",
    "    char_encoding_result = chardet.detect(rawdata.read(100000))\n",
    "char_encoding_result\n",
    "assert char_encoding_result\n",
    "encoding = char_encoding_result['encoding']\n",
    "assert encoding\n",
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_file = open(naics_structure_filename, encoding=encoding)\n",
    "csvreader = csv.reader(structure_file)\n",
    "header = []\n",
    "header = next(csvreader)\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(naics_structure_filename, newline='', encoding=encoding) as csvfile:\n",
    "    # map custom field names that match database field names\n",
    "    field_names = ['level', 'hierarchical_structure', 'code', 'class_title', 'superscript', 'class_definition']\n",
    "    reader = csv.DictReader(csvfile, fieldnames=field_names)\n",
    "    # The line will skip the first row of the csv file (Header row)\n",
    "    next(reader)\n",
    "    structure_dict_arr = []\n",
    "\n",
    "    try:\n",
    "        if generate_subset_of_naics_data:\n",
    "            for row in reader:\n",
    "                code = row['code']\n",
    "                if code in codes_to_add:\n",
    "                    # print(f'code is match: {code}')\n",
    "                    # add custom properties to data row\n",
    "                    row['year'] = naics_year\n",
    "                    row['version'] = naics_version\n",
    "                    row['naics_key'] = str(uuid.uuid4())\n",
    "                    structure_dict_arr.append(row)\n",
    "            print(structure_dict_arr)\n",
    "        else:\n",
    "            for row in reader:\n",
    "                # add custom properties to data row\n",
    "                row['year'] = naics_year\n",
    "                row['version'] = naics_version\n",
    "                row['naics_key'] = str(uuid.uuid4())\n",
    "                structure_dict_arr.append(row)\n",
    "            print(structure_dict_arr)\n",
    "    except csv.Error as e:\n",
    "        sys.exit('file {}, line {}: {}'.format(filename, reader.line_num, e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dict from NAICS element data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_file = open(naics_element_filename)\n",
    "csvreader = csv.reader(structure_file)\n",
    "header = []\n",
    "header = next(csvreader)\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note in order for this to work, need to update ~/.jupyter/jupyter_notebook_config.py by adding c.NotebookApp.iopub_data_rate_limit = 10000000\n",
    "# if not done, an error message is thrown indicating streaming data rate exceeded\n",
    "with open(naics_element_filename, newline='') as csvfile:\n",
    "    # map custom field names that match database field names\n",
    "    field_names = ['level', 'code', 'class_title', 'element_type_label', 'element_description']\n",
    "    reader = csv.DictReader(csvfile, fieldnames=field_names)\n",
    "    # The line will skip the first row of the csv file (Header row)\n",
    "    next(reader)\n",
    "    element_dict_arr = []\n",
    "\n",
    "    try:\n",
    "        if generate_subset_of_naics_data:\n",
    "            for row in reader:\n",
    "                code = row['code']\n",
    "                if code in codes_to_add:\n",
    "                    # print(f'code is match: {code}')\n",
    "                    # add custom properties to data row\n",
    "                    row['year'] = naics_year\n",
    "                    row['version'] = naics_version\n",
    "                    row['element_type'] = get_element_type_from_label(row['element_type_label'])\n",
    "                    del row['element_type_label']\n",
    "                    element_dict_arr.append(row)\n",
    "            print(element_dict_arr)\n",
    "        else:\n",
    "            for row in reader:\n",
    "                # add custom properties to data row\n",
    "                row['year'] = naics_year\n",
    "                row['version'] = naics_version\n",
    "                row['element_type'] = get_element_type_from_label(row['element_type_label'])\n",
    "                del row['element_type_label']\n",
    "                element_dict_arr.append(row)\n",
    "            print(element_dict_arr)\n",
    "    except csv.Error as e:\n",
    "        sys.exit('file {}, line {}: {}'.format(filename, reader.line_num, e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}